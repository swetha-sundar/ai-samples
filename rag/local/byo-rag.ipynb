{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own RAG application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: anyio in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from httpx<0.29,>=0.27->ollama) (3.6.2)\n",
      "Requirement already satisfied: certifi in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from httpx<0.29,>=0.27->ollama) (2022.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from httpx<0.29,>=0.27->ollama) (3.3)\n",
      "Requirement already satisfied: sniffio in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from httpx<0.29,>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/swsundar/opt/miniconda3/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into memory from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 150 entries\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open('data/cat-facts.txt', 'r') as file:\n",
    "    dataset = file.readlines()\n",
    "    print(f\" Loaded {len(dataset)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the embeddings for the dataset\n",
    "\n",
    "- Uses the BAAI text embedding model\n",
    "- Chunking: each entry line in the dataset is treated as a chunk\n",
    "- Convert each chunk into an embedding vector \n",
    "- Store the chunk and its corresponding vector into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "em = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "lm = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'\n",
    "\n",
    "# Each element in the vector_db will be a tuple (chunk, embedding)\n",
    "# The embedding is a list of floats, for example: [0.1, 0.04, -0.34, 0.21, ...]\n",
    "vector_db = []\n",
    "\n",
    "def add_chunk_to_database(chunk):\n",
    "  embedding = ollama.embed(model=em, input=chunk)['embeddings'][0]\n",
    "  vector_db.append((chunk, embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chunk 1/150 to the database\n",
      "Added chunk 2/150 to the database\n",
      "Added chunk 3/150 to the database\n",
      "Added chunk 4/150 to the database\n",
      "Added chunk 5/150 to the database\n",
      "Added chunk 6/150 to the database\n",
      "Added chunk 7/150 to the database\n",
      "Added chunk 8/150 to the database\n",
      "Added chunk 9/150 to the database\n",
      "Added chunk 10/150 to the database\n",
      "Added chunk 11/150 to the database\n",
      "Added chunk 12/150 to the database\n",
      "Added chunk 13/150 to the database\n",
      "Added chunk 14/150 to the database\n",
      "Added chunk 15/150 to the database\n",
      "Added chunk 16/150 to the database\n",
      "Added chunk 17/150 to the database\n",
      "Added chunk 18/150 to the database\n",
      "Added chunk 19/150 to the database\n",
      "Added chunk 20/150 to the database\n",
      "Added chunk 21/150 to the database\n",
      "Added chunk 22/150 to the database\n",
      "Added chunk 23/150 to the database\n",
      "Added chunk 24/150 to the database\n",
      "Added chunk 25/150 to the database\n",
      "Added chunk 26/150 to the database\n",
      "Added chunk 27/150 to the database\n",
      "Added chunk 28/150 to the database\n",
      "Added chunk 29/150 to the database\n",
      "Added chunk 30/150 to the database\n",
      "Added chunk 31/150 to the database\n",
      "Added chunk 32/150 to the database\n",
      "Added chunk 33/150 to the database\n",
      "Added chunk 34/150 to the database\n",
      "Added chunk 35/150 to the database\n",
      "Added chunk 36/150 to the database\n",
      "Added chunk 37/150 to the database\n",
      "Added chunk 38/150 to the database\n",
      "Added chunk 39/150 to the database\n",
      "Added chunk 40/150 to the database\n",
      "Added chunk 41/150 to the database\n",
      "Added chunk 42/150 to the database\n",
      "Added chunk 43/150 to the database\n",
      "Added chunk 44/150 to the database\n",
      "Added chunk 45/150 to the database\n",
      "Added chunk 46/150 to the database\n",
      "Added chunk 47/150 to the database\n",
      "Added chunk 48/150 to the database\n",
      "Added chunk 49/150 to the database\n",
      "Added chunk 50/150 to the database\n",
      "Added chunk 51/150 to the database\n",
      "Added chunk 52/150 to the database\n",
      "Added chunk 53/150 to the database\n",
      "Added chunk 54/150 to the database\n",
      "Added chunk 55/150 to the database\n",
      "Added chunk 56/150 to the database\n",
      "Added chunk 57/150 to the database\n",
      "Added chunk 58/150 to the database\n",
      "Added chunk 59/150 to the database\n",
      "Added chunk 60/150 to the database\n",
      "Added chunk 61/150 to the database\n",
      "Added chunk 62/150 to the database\n",
      "Added chunk 63/150 to the database\n",
      "Added chunk 64/150 to the database\n",
      "Added chunk 65/150 to the database\n",
      "Added chunk 66/150 to the database\n",
      "Added chunk 67/150 to the database\n",
      "Added chunk 68/150 to the database\n",
      "Added chunk 69/150 to the database\n",
      "Added chunk 70/150 to the database\n",
      "Added chunk 71/150 to the database\n",
      "Added chunk 72/150 to the database\n",
      "Added chunk 73/150 to the database\n",
      "Added chunk 74/150 to the database\n",
      "Added chunk 75/150 to the database\n",
      "Added chunk 76/150 to the database\n",
      "Added chunk 77/150 to the database\n",
      "Added chunk 78/150 to the database\n",
      "Added chunk 79/150 to the database\n",
      "Added chunk 80/150 to the database\n",
      "Added chunk 81/150 to the database\n",
      "Added chunk 82/150 to the database\n",
      "Added chunk 83/150 to the database\n",
      "Added chunk 84/150 to the database\n",
      "Added chunk 85/150 to the database\n",
      "Added chunk 86/150 to the database\n",
      "Added chunk 87/150 to the database\n",
      "Added chunk 88/150 to the database\n",
      "Added chunk 89/150 to the database\n",
      "Added chunk 90/150 to the database\n",
      "Added chunk 91/150 to the database\n",
      "Added chunk 92/150 to the database\n",
      "Added chunk 93/150 to the database\n",
      "Added chunk 94/150 to the database\n",
      "Added chunk 95/150 to the database\n",
      "Added chunk 96/150 to the database\n",
      "Added chunk 97/150 to the database\n",
      "Added chunk 98/150 to the database\n",
      "Added chunk 99/150 to the database\n",
      "Added chunk 100/150 to the database\n",
      "Added chunk 101/150 to the database\n",
      "Added chunk 102/150 to the database\n",
      "Added chunk 103/150 to the database\n",
      "Added chunk 104/150 to the database\n",
      "Added chunk 105/150 to the database\n",
      "Added chunk 106/150 to the database\n",
      "Added chunk 107/150 to the database\n",
      "Added chunk 108/150 to the database\n",
      "Added chunk 109/150 to the database\n",
      "Added chunk 110/150 to the database\n",
      "Added chunk 111/150 to the database\n",
      "Added chunk 112/150 to the database\n",
      "Added chunk 113/150 to the database\n",
      "Added chunk 114/150 to the database\n",
      "Added chunk 115/150 to the database\n",
      "Added chunk 116/150 to the database\n",
      "Added chunk 117/150 to the database\n",
      "Added chunk 118/150 to the database\n",
      "Added chunk 119/150 to the database\n",
      "Added chunk 120/150 to the database\n",
      "Added chunk 121/150 to the database\n",
      "Added chunk 122/150 to the database\n",
      "Added chunk 123/150 to the database\n",
      "Added chunk 124/150 to the database\n",
      "Added chunk 125/150 to the database\n",
      "Added chunk 126/150 to the database\n",
      "Added chunk 127/150 to the database\n",
      "Added chunk 128/150 to the database\n",
      "Added chunk 129/150 to the database\n",
      "Added chunk 130/150 to the database\n",
      "Added chunk 131/150 to the database\n",
      "Added chunk 132/150 to the database\n",
      "Added chunk 133/150 to the database\n",
      "Added chunk 134/150 to the database\n",
      "Added chunk 135/150 to the database\n",
      "Added chunk 136/150 to the database\n",
      "Added chunk 137/150 to the database\n",
      "Added chunk 138/150 to the database\n",
      "Added chunk 139/150 to the database\n",
      "Added chunk 140/150 to the database\n",
      "Added chunk 141/150 to the database\n",
      "Added chunk 142/150 to the database\n",
      "Added chunk 143/150 to the database\n",
      "Added chunk 144/150 to the database\n",
      "Added chunk 145/150 to the database\n",
      "Added chunk 146/150 to the database\n",
      "Added chunk 147/150 to the database\n",
      "Added chunk 148/150 to the database\n",
      "Added chunk 149/150 to the database\n",
      "Added chunk 150/150 to the database\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(dataset):\n",
    "  add_chunk_to_database(chunk)\n",
    "  print(f'Added chunk {i+1}/{len(dataset)} to the database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval/Knowledge Extraction\n",
    "\n",
    "I/P: Query\n",
    "O/P: Returns the top N most relevant chunks\n",
    "\n",
    "\"Relevant\" chunks - based on cosine similarity\n",
    "Higher the cosine similarity between  the two vectors, they are more similar in terms of meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "  dot_product = sum([x * y for x, y in zip(a, b)])\n",
    "  norm_a = sum([x ** 2 for x in a]) ** 0.5\n",
    "  norm_b = sum([x ** 2 for x in b]) ** 0.5\n",
    "  return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "  query_embedding = ollama.embed(model=em, input=query)['embeddings'][0]\n",
    "  # temporary list to store (chunk, similarity) pairs\n",
    "  similarities = []\n",
    "  for chunk, embedding in vector_db:\n",
    "    similarity = cosine_similarity(query_embedding, embedding)\n",
    "    similarities.append((chunk, similarity))\n",
    "  # sort by similarity in descending order, because higher similarity means more relevant chunks\n",
    "  similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "  # finally, return the top N most relevant chunks\n",
    "  return similarities[:top_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the input Query and Retrieve relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved knowledge:\n",
      " - (similarity: 0.82) The most popular pedigreed cat is the Persian cat, followed by the Main Coon cat and the Siamese cat.\n",
      "\n",
      " - (similarity: 0.76) Today there are about 100 distinct breeds of the domestic cat.\n",
      "\n",
      " - (similarity: 0.76) Cats are North Americaâ€™s most popular pets: there are 73 million cats compared to 63 million dogs. Over 30% of households in North America own a cat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Ask me a question: ')\n",
    "retrieved_knowledge = retrieve(input_query)\n",
    "\n",
    "print('Retrieved knowledge:')\n",
    "for chunk, similarity in retrieved_knowledge:\n",
    "  print(f' - (similarity: {similarity:.2f}) {chunk}')\n",
    "\n",
    "new_line = '\\n'\n",
    "instruction_prompt = f'''You are a helpful chatbot.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{new_line.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
    "'''\n",
    "\n",
    "#print(instruction_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a response based on retrieved knowledge \n",
    "Use `ollama` to generate the response based on the instruction_prompt as system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "According to the two pieces of context, we can infer that the popular cat breeds in North America are:\n",
      "\n",
      "1. Persian\n",
      "2. Main Coon\n",
      "3. Siamese"
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "  model=lm,\n",
    "  messages=[\n",
    "    {'role': 'system', 'content': instruction_prompt},\n",
    "    {'role': 'user', 'content': input_query},\n",
    "  ],\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "# print the response from the chatbot in real-time\n",
    "print('Chatbot response:')\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
